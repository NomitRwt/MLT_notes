[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MLT Notes",
    "section": "",
    "text": "Note\n\n\n\nThis site is still under development.\n\n\nTable of Contents:\n\nIntroduction; Unsupervised Learning - Representation learning - PCA\nUnsupervised Learning - Representation learning - Kernel PCA\nUnsupervised Learning - Clustering - K-means/Kernel K-means\nUnsupervised Learning - Estimation - Recap of MLE + Bayesian estimation, Gaussian Mixture Model - EM algorithm\nSupervised Learning - Regression - Least Squares; Bayesian view\nSupervised Learning - Regression - Ridge/LASSO\nSupervised Learning - Classification - K-NN, Decision tree"
  },
  {
    "objectID": "pages/Wk04.html",
    "href": "pages/Wk04.html",
    "title": "Unsupervised Learning - Estimation - Recap of MLE + Bayesian estimation, Gaussian Mixture Model - EM algorithm",
    "section": "",
    "text": "PDF Link: notes"
  },
  {
    "objectID": "pages/Wk04.html#fishers-principle-of-maximum-likelihood",
    "href": "pages/Wk04.html#fishers-principle-of-maximum-likelihood",
    "title": "Unsupervised Learning - Estimation - Recap of MLE + Bayesian estimation, Gaussian Mixture Model - EM algorithm",
    "section": "Fisher’s Principle of Maximum Likelihood",
    "text": "Fisher’s Principle of Maximum Likelihood\nFisher’s principle of maximum likelihood is a statistical method used to estimate the parameters of a statistical model by choosing the parameter values that maximize the likelihood function, which measures how well the model fits the observed data.\nApplying the likelihood function on the above dataset, we get \\[\\begin{align*}\n\\mathcal{L}(p;\\{x_1, x_2, \\ldots, x_n\\}) &= P(x_1, x_2, \\ldots, x_n;p)\\\\\n&=p(x_1;p)p(x_2;p)\\ldots p(x_n;p) \\\\\n&=\\prod _{i=1} ^n {p^{x_i}(1-p)^{1-x_i}}\n\\end{align*}\\] \\[\\begin{align*}\n\\therefore \\log(\\mathcal{L}(p;\\{x_1, x_2, \\ldots, x_n\\})) &=\\underset{p} {\\arg \\max}\\log \\left ( \\prod _{i=1} ^n {p^{x_i}(1-p)^{1-x_i}} \\right ) \\\\\n\\text{Differentiating wrt $p$, we get}\\\\\n\\therefore \\hat{p}_{ML} &= \\frac{1}{n}\\sum _{i=1} ^n x_i\n\\end{align*}\\]"
  },
  {
    "objectID": "pages/Wk04.html#likelihood-estimation-on-gaussian-distributions",
    "href": "pages/Wk04.html#likelihood-estimation-on-gaussian-distributions",
    "title": "Unsupervised Learning - Estimation - Recap of MLE + Bayesian estimation, Gaussian Mixture Model - EM algorithm",
    "section": "Likelihood Estimation on Gaussian Distributions",
    "text": "Likelihood Estimation on Gaussian Distributions\nLet \\(\\{x_1, x_2, \\ldots, x_n\\}\\) be a dataset where \\(x_i \\sim \\mathcal{N}(\\mu,\\sigma^2)\\). We assume that the datapoints are independent and identically distributed.\n\\[\\begin{align*}\n\\mathcal{L}(\\mu, \\sigma^2;\\{x_1, x_2, \\ldots, x_n\\}) &= f_{x_1, x_2, \\ldots, x_n}(x_1, x_2, \\ldots, x_n;\\mu, \\sigma^2) \\\\\n&=\\prod _{i=1} ^n  f_{x_i}(x_i;\\mu, \\sigma^2) \\\\\n&=\\prod _{i=1} ^n \\left [ \\frac{1}{\\sqrt{2\\pi}\\sigma} e^{\\frac{-(x_i-\\mu)^2}{2\\sigma^2}} \\right ] \\\\\n\\therefore \\log(\\mathcal{L}(p;\\{x_1, x_2, \\ldots, x_n\\})) &= \\sum _{i=1} ^n \\left[ \\log \\left (\\frac{1}{\\sqrt{2\\pi}\\sigma}  \\right ) - \\frac{(x_i-\\mu)^2}{2\\sigma^2} \\right] \\\\\n\\end{align*}\\] \\[\n\\text{Differentiating wrt $\\mu$ and $\\sigma$, we get}\n\\] \\[\\begin{align*}\n\\hat{\\mu}_{ML} &= \\frac{1}{n}\\sum _{i=1} ^n x_i \\\\\n\\hat{\\sigma^2}_{ML} &= \\frac{1}{n}\\sum _{i=1} ^n (x_i-\\mu)^2\n\\end{align*}\\]"
  },
  {
    "objectID": "pages/Wk04.html#convexity-and-jensens-inequality",
    "href": "pages/Wk04.html#convexity-and-jensens-inequality",
    "title": "Unsupervised Learning - Estimation - Recap of MLE + Bayesian estimation, Gaussian Mixture Model - EM algorithm",
    "section": "Convexity and Jensen’s Inequality",
    "text": "Convexity and Jensen’s Inequality\nConvexity is a property of a function or set that implies a unique line segment can be drawn between any two points within the function or set. For a concave function, this property can be expressed as, \\[\nf \\left (\\sum _{k=1} ^K \\lambda_k a_k \\right ) \\ge \\sum _{k=1} ^K \\lambda_k f(a_k)\n\\] where \\[\n\\sum _{k=1} ^K \\lambda _k = 1\n\\] \\[\na_k \\text{ are points of the function}\n\\] This is also known as Jensen’s Inequality."
  },
  {
    "objectID": "pages/Wk05.html",
    "href": "pages/Wk05.html",
    "title": "Supervised Learning - Regression - Least Squares; Bayesian view",
    "section": "",
    "text": "PDF Link: notes"
  },
  {
    "objectID": "pages/Wk05.html#stochastic-gradient-descent",
    "href": "pages/Wk05.html#stochastic-gradient-descent",
    "title": "Supervised Learning - Regression - Least Squares; Bayesian view",
    "section": "Stochastic Gradient Descent",
    "text": "Stochastic Gradient Descent\nStochastic gradient descent (SGD) is an optimization algorithm used in machine learning for finding the parameters that minimize the loss function of a model. In contrast to traditional gradient descent, which updates the model parameters based on the entire dataset, SGD updates the parameters based on a randomly selected subset of the data, known as a batch. This results in faster training times and makes SGD particularly useful for large datasets.\nFor every step \\(t\\), rather than updating \\(w\\) using the entire dataset, we use a small randomly selected (\\(k\\)) data points to update \\(w\\). Therefore, the new gradient is \\(2(\\tilde{X}\\tilde{X}^Tw^t - \\tilde{X}\\tilde{y})\\) where \\(\\tilde{X}\\) and \\(\\tilde{y}\\) is the small sample randomly selected from the dataset. This is manageable because \\(\\tilde{X} \\in \\mathbb{R}^{d \\times k}\\) which is considerably smaller that \\(X\\).\nAfter T rounds, we use, \\[\nw ^T _{SGD} = \\frac{1}{T}  \\sum _{i=1} ^T w^i\n\\] This has a certain guarantee to have optimal convergence partly because of the randomness involved in it."
  },
  {
    "objectID": "pages/Wk06.html",
    "href": "pages/Wk06.html",
    "title": "Supervised Learning - Regression - Ridge/LASSO",
    "section": "",
    "text": "Note\n\n\n\nThis page is still under development.\n\n\n\nGoodness of Maximum Likelihood Estimator for linear regression\nGiven a dataset \\(\\{x_1, \\ldots, x_n\\}\\) where \\(x_i \\in \\mathbb{R}^d\\), let \\(\\{y_1, \\ldots, y_n\\}\\) be the labels, where \\(y_i \\in \\mathbb{R}\\). \\[\ny|X = w^Tx + \\epsilon\n\\] where \\(\\epsilon \\sim \\mathcal{N}(0,\\sigma^2)\\) and \\(w \\in \\mathbb{R}^d\\). Let \\(\\hat{w}_{ML}\\) signify the maximum likelihood parameter for linear regression. \\[\n\\hat{w}_{ML}=w^*=(XX^T)^+Xy\n\\] \\(\\therefore\\) To measure how good our parameter is, we use the follow: \\[\n\\mathbb{E} [|| \\hat{w}_{ML} - w ||^2_2]\n\\] This is known as the Mean Squared Error (MSE) and turns out to be equal to \\[\n\\mathbb{E} [|| \\hat{w}_{ML} - w ||^2_2] = \\sigma^2 *trace((XX^T)^{-1})\n\\]\n\n\nCross-validation for minimizing MSE\nLet the eigenvalues of \\(XX^T\\) be \\(\\{\\lambda_1, \\ldots, \\lambda_d\\}\\). Hence the eigenvalues of \\((XX^T)^{-1}\\) are \\(\\{\\frac{1}{\\lambda_1}, \\ldots, \\frac{1}{\\lambda_d}\\}\\).\n\\(\\therefore\\) The MSE is, \\[\n\\mathbb{E} [|| \\hat{w}_{ML} - w ||^2_2] = \\sigma^2 \\sum_{i=1}^d  \\frac{1}{\\lambda_i}\n\\] Consider the following estimator, \\[\n\\hat{w}_{new}=(XX^T + \\lambda I)^+Xy\n\\] where \\(\\lambda \\in \\mathbb{R}\\) and \\(I \\in \\mathbb{R}^{d\\times d}\\) is the Identity Matrix. Using this we get, \\[\ntrace((XX^T + \\lambda I)^{-1}) = \\sum_{i=1}^d  \\frac{1}{\\lambda_i + \\lambda}\n\\] According to the Existence Theorem,"
  },
  {
    "objectID": "pages/Wk07.html",
    "href": "pages/Wk07.html",
    "title": "Supervised Learning - Classification - K-NN, Decision tree",
    "section": "",
    "text": "PDF Link: notes"
  },
  {
    "objectID": "pages/Wk07.html#issues-with-k-nn",
    "href": "pages/Wk07.html#issues-with-k-nn",
    "title": "Supervised Learning - Classification - K-NN, Decision tree",
    "section": "Issues with K-NN",
    "text": "Issues with K-NN\nFollowing are the issues with the algorithm:\n\nThe choice of distance function itself can give different results. The Euclidean distance might not always be the best fit!\nIt can be computationally demanding. When making a prediction for a single test datapoint, the distances between that datapoint and all training points must be calculated and sorted. As a result, the algorithm has a complexity of \\(O(nlog(n))\\), where \\(n\\) represents the size of the dataset.\nNo model is learned by this algorithm. It always needs the training dataset to make proper predictions."
  },
  {
    "objectID": "pages/Wk07.html#goodness-of-a-question",
    "href": "pages/Wk07.html#goodness-of-a-question",
    "title": "Supervised Learning - Classification - K-NN, Decision tree",
    "section": "Goodness of a Question",
    "text": "Goodness of a Question\nLet \\(D=\\{(x_1, y_1), \\ldots, (x_n,y_n)\\}\\) be the dataset. We partition it using a question into \\(D_{yes}\\) and \\(D_{no}\\).\nWhat we need is a measure of “Impurity” for a set of labels \\(\\{y_1, \\ldots, y_n\\}\\). This measure can be given by various ways, but we will use the Entropy Function.\nThe Entropy function is given by, \\[\nEntropy(\\{y_1, \\ldots, y_n\\}) = Entropy(p) = -\\left( p\\log(p)+(1-p)\\log(1-p) \\right )\n\\] where conventionally \\(\\log(0)\\) is treated as \\(0\\).\nPictorial Representation of the Entropy function:\n\n\n\nEntropy Function\n\n\nThen, we use Information Gain to measure the goodness of the split.\nInformation gain is a commonly used criterion in decision tree algorithms that measures the reduction in entropy or impurity of a dataset after splitting based on a given feature. By selecting features with high information gain, decision trees can effectively differentiate between the different classes of data and make accurate predictions.\nInformation gain is given by, \\[\n\\text{Information Gain}(feature,value)=Entropy(D) - \\left [ \\gamma Entropy(D_{yes})+(1-\\gamma)Entropy(D_{no}) \\right ]\n\\] where \\(\\gamma\\) is given by, \\[\n\\gamma=\\frac{|D_{yes}|}{|D|}\n\\]"
  },
  {
    "objectID": "pages/Wk07.html#decision-tree-algorithm",
    "href": "pages/Wk07.html#decision-tree-algorithm",
    "title": "Supervised Learning - Classification - K-NN, Decision tree",
    "section": "Decision Tree Algorithm",
    "text": "Decision Tree Algorithm\nThe algorithm is as follows:\n\nDiscretize each feature in [min,max] range.\nPick the question that has the largest information gain.\nRepeat the procedure for \\(D_{yes}\\) and \\(D_{no}\\).\nStop growing the tree if a node becomes sufficiently “pure”.\n\nThe goodness of a question can also be measured using different methods like the Gini Index, etc.\nPictorial Depiction of decision boundary and its decision tree:\n\n\n\nDecision Boundary"
  },
  {
    "objectID": "pages/Wk01.html",
    "href": "pages/Wk01.html",
    "title": "Introduction; Unsupervised Learning - Representation learning - PCA",
    "section": "",
    "text": "PDF Link: notes"
  },
  {
    "objectID": "pages/Wk01.html#broad-paradigms-of-machine-learning",
    "href": "pages/Wk01.html#broad-paradigms-of-machine-learning",
    "title": "Introduction; Unsupervised Learning - Representation learning - PCA",
    "section": "Broad Paradigms of Machine Learning",
    "text": "Broad Paradigms of Machine Learning\n\nSupervised Learning:Supervised Machine Learning is a type of machine learning where the algorithm is trained on a labeled dataset, meaning that the data includes both inputs and their corresponding outputs. The goal of supervised learning is to build a model that can accurately predict the output for new, unseen input data. Few examples:\n\n\nLinear regression for predicting a continuous output\nLogistic regression for binary classification problems\nDecision trees for non-linear classification and regression problems\nSupport Vector Machines for binary and multi-class classification problems\nNeural Networks for complex non-linear problems in various domains such as computer vision, natural language processing, and speech recognition\n\n\nUnsupervised Learning: Unsupervised Machine Learning is a type of machine learning where the algorithm is trained on an unlabeled dataset, meaning that only the inputs are provided and no corresponding outputs. The goal of unsupervised learning is to uncover patterns or relationships within the data without any prior knowledge or guidance. Few examples:\n\n\nClustering algorithms such as K-means, hierarchical clustering, and density-based clustering, used to group similar data points together into clusters\nDimensionality reduction techniques such as Principal Component Analysis (PCA), used to reduce the number of features in a dataset while preserving the maximum amount of information\nAnomaly detection algorithms used to identify unusual data points that deviate from the normal patterns in the data\n\n\nSequential learning: Sequential Machine Learning (also known as time-series prediction) is a type of machine learning that is focused on making predictions based on sequences of data. It involves training the model on a sequence of inputs, such that the predictions for each time step depend on the previous time steps. Few examples:\n\n\nTime series forecasting, used to predict future values based on past trends and patterns in data such as stock prices, weather patterns, and energy consumption\nSpeech recognition, used to transcribe speech into text by recognizing patterns in audio signals\nNatural language processing, used to analyze and make predictions about sequences of text data"
  },
  {
    "objectID": "pages/Wk01.html#potential-algorithm",
    "href": "pages/Wk01.html#potential-algorithm",
    "title": "Introduction; Unsupervised Learning - Representation learning - PCA",
    "section": "Potential Algorithm",
    "text": "Potential Algorithm\nWith this information, we can give the following algorithm:\\ Given a dataset \\(\\{x_1, x_2, \\ldots, x_n\\}\\) where \\(x_i \\in \\mathbb{R}^{d}\\),\n\nCenter the dataset \\[\n\\mu = \\frac{1}{n} \\sum _{i=1} ^{n} x_i\n\\] \\[\nx_i = x_i - \\mu  \\hspace{2em} \\forall i\n\\]\nFind the best representation \\(w \\in \\mathbb{R}^d\\) and \\(||w|| = 1\\).\nReplace \\(x_i = x_i - (x_i^Tw)w \\hspace{1em} \\forall i\\)\nRepeat the first three steps until residues become zero and we obtain \\(w_2, w_3, \\ldots, w_d\\).\n\nBut is this the best way? How many \\(w\\) do we need for optimal compression?"
  },
  {
    "objectID": "pages/Wk01.html#approximate-representation",
    "href": "pages/Wk01.html#approximate-representation",
    "title": "Introduction; Unsupervised Learning - Representation learning - PCA",
    "section": "Approximate Representation",
    "text": "Approximate Representation\nIf the data can be approximately represented by a lower sub-space, is it enough that we use only those \\(K\\) projections? How much variance should be covered?\nGiven a centered dataset \\(\\{x_1, x_2, \\ldots, x_n\\}\\) where \\(x_i \\in \\mathbb{R}^{d}\\), let \\(C\\) be its covariance matrix, and let \\(\\{\\lambda_1, \\lambda_2, \\ldots, \\lambda_d \\}\\) be its eigenvalues, which are non-negative because the covariance matrix is a positive semi-definite matrix, placed in descending order, and let \\(\\{w_1, w_2, \\ldots, w_d \\}\\) be its corresponding eigenvectors of unit length.\nThe eigen equation for the covariance matrix can be given by, \\[\\begin{align*}\n    Cw &= \\lambda w \\\\\n    w^TCw &= w^T\\lambda w\\\\\n    \\therefore \\lambda &= w^TCw \\hspace{2em} \\{w^Tw = 1\\} \\\\\n    \\lambda &= \\frac{1}{n} \\sum _{i=1} ^{n} (x_i^Tw)^2 \\\\\n\\end{align*}\\] Therefore, as the mean is zero, \\(\\lambda\\) gives the variance captured by the eigenvector \\(w\\).\nA good rule of thumb is that the variance captured by P.C.A. should be at least 95%. If the first \\(K\\) eigenvectors capture the required variance, this is given by, \\[\n\\frac{\\displaystyle \\sum _{k=1} ^{K} \\lambda_k}{\\displaystyle \\sum _{i=1} ^{d} \\lambda_i} \\ge 0.95\n\\] Hence, the higher the variance captured, the lower is the error obtained."
  },
  {
    "objectID": "pages/Wk01.html#p.c.a.-algorithm",
    "href": "pages/Wk01.html#p.c.a.-algorithm",
    "title": "Introduction; Unsupervised Learning - Representation learning - PCA",
    "section": "P.C.A. Algorithm",
    "text": "P.C.A. Algorithm\nGiven a centered dataset \\(\\{x_1, x_2, \\ldots, x_n\\}\\) where \\(x_i \\in \\mathbb{R}^{d}\\), let \\(C\\) be its covariance matrix.\\ The algorithm is as follows:\n\nStep 1: Find the eigenvalues and eigenvectors of \\(C\\). Let \\(\\{\\lambda_1, \\lambda_2, \\ldots, \\lambda_d \\}\\) be its eigenvalues placed in the descending order, and let \\(\\{w_1, w_2, \\ldots, w_d \\}\\) be its corresponding eigenvectors of unit length.\nStep 2: Calculate \\(K\\), where \\(K\\) is the number of required top eigenvalues and eigenvectors, according to the required variance that needs to be covered.\nStep 3: Project the data onto the eigenvectors, and obtain the required representation as a linear combination of those projections.\n\nIn short, we can say that P.C.A. is a dimensionality reduction technique that finds combination of features that are de-correlated (independent of each other)."
  },
  {
    "objectID": "pages/Wk02.html",
    "href": "pages/Wk02.html",
    "title": "Unsupervised Learning - Representation learning - Kernel PCA",
    "section": "",
    "text": "PDF Link: notes"
  },
  {
    "objectID": "pages/Wk02.html#transforming-features",
    "href": "pages/Wk02.html#transforming-features",
    "title": "Unsupervised Learning - Representation learning - Kernel PCA",
    "section": "Transforming Features",
    "text": "Transforming Features\nWe solve the problem of non-linear relationships by mapping them to higher dimensions. \\[\nx \\to \\phi(x) \\hspace{2em} \\mathbb{R} ^d \\to \\mathbb{R} ^D \\hspace{2em} \\text{where } [D >> d]\n\\] To compute \\(D\\):\nLet \\(x=\\left [ \\begin{array} {cc}  f_1 & f_2 \\end{array} \\right ]\\) be features of a dataset containing datapoints lying on a curve of degree two in a two-dimensional space.\nTo make it linear from quadratic, we map the features to \\(\\phi(x)=\\left [ \\begin{array} {cccccc}  1 & f_1^2 & f_2^2 & f_1f_2 & f_1 & f_2 \\end{array} \\right ]\\)\nMapping \\(d\\) features to the polygonial power \\(p\\) gives \\(^{d+p} C_d\\) new features.\nIssue: Finding \\(\\phi(x)\\) may be very hard.\nSolution for this issue is in the next point."
  },
  {
    "objectID": "pages/Wk02.html#kernel-functions",
    "href": "pages/Wk02.html#kernel-functions",
    "title": "Unsupervised Learning - Representation learning - Kernel PCA",
    "section": "Kernel Functions",
    "text": "Kernel Functions\nA function that maps \\(k: \\mathbb{R}^d \\times \\mathbb{R}^d \\to \\mathbb{R}\\), and is a “valid”, is called a Kernel Function.\\ Proof of a “Valid” Kernel:\n\nMethod 1: Exhibit the map to \\(\\phi\\) explicitly. [may be hard]\nMethod 2: Using Mercer’s Theorem:\n\n\\(k: \\mathbb{R}^d \\times \\mathbb{R}^d \\to \\mathbb{R}\\) is a “valid” kernel if and only if:\n\n\\(k\\) is symmetric i.e \\(k(x,x') = k(x',x)\\)\nFor any dataset \\(\\{x_1,x_2,\\ldots,x_n \\}\\), the matrix \\(K \\in \\mathbb{R}^{n \\times n}\\), where \\(K_{ij} = k(i,j)\\), is Positive Semi-Definite.\n\n\n\nTwo Popular Kernel Functions: * Polynomial Kernel: \\(k(x,x') = (x^Tx + 1)^p\\) * Radial Basis Function Kernel or Gaussian Kernel: \\(exp(-\\frac{||x-x'||^2}{2\\sigma^2})\\)"
  },
  {
    "objectID": "pages/Wk03.html",
    "href": "pages/Wk03.html",
    "title": "Unsupervised Learning - Clustering - K-means/Kernel K-means",
    "section": "",
    "text": "PDF Link: notes"
  },
  {
    "objectID": "pages/Wk03.html#the-algorithm",
    "href": "pages/Wk03.html#the-algorithm",
    "title": "Unsupervised Learning - Clustering - K-means/Kernel K-means",
    "section": "The Algorithm",
    "text": "The Algorithm\nThe algorithm is as follows:\nStep 1: Initialization: Assign \\(z_1^0, z_2^0, \\ldots, z_n^0\\) where \\(z_i^0 \\in \\{1, 2, \\ldots, k\\}\\). The approach on how to initialize them is discussed later.\nStep 2: Compute Means: \\[\n\\mu _k ^t = \\frac{\\displaystyle \\sum _{i = 1} ^{n} {x_i \\cdot \\mathbf{1}(z_i^t=k)}}{\\displaystyle \\sum _{i = 1} ^{n} {\\mathbf{1}(z_i^t=k)}} \\hspace{2em} \\forall k\n\\]\nStep 3: Reassignment Step: \\[\nz _i ^{t+1} = \\underset{k}{\\arg \\min} {|| x_i - \\mu _{k} ^t ||}_2 ^2 \\hspace{2em} \\forall i\n\\]\nStep 4: Loop until Convergence: Repeat steps 2 and 3 until convergence for \\(t\\) iterations."
  },
  {
    "objectID": "pages/Wk03.html#fact-regarding-lloyds-algorithm",
    "href": "pages/Wk03.html#fact-regarding-lloyds-algorithm",
    "title": "Unsupervised Learning - Clustering - K-means/Kernel K-means",
    "section": "Fact regarding Lloyd’s Algorithm",
    "text": "Fact regarding Lloyd’s Algorithm\nLloyd’s Algorithm, also known as K-means, is guaranteed to converge to a solution. While the converged solution may not be the optimal one, it has been observed to produce acceptable clustering results in practice."
  }
]